Soon:

[GUI] mark vertical scale units in the trace pane:
a long label might be "spark creation/conversion rate, unit spark/ms"
or "fizzled sparks/millisecond" or "Spark creation rate (sparks/millisecond)"

[GUI] in the key, label the coloured areas, according to what they represent
the title of the plot is "spark creation rate" and the key will have things
for each colour; separate sections of the Key for
the activity vs sparks vs next-thing; make sure the user understands
that the _areas_ are proportional to the total number and graphs to rates

[GUI] either fix tickboxes for HEC sets or make it two dimensional: one column
of tickboxes for activity, one column for spark creation, spark conversion


Later:

fix the scarcity of sample data for cap 1 in our example event log

[GUI] put all the HEC0 bits together, both in the trace and in the timeline view
ie in the timeline, top -> bottom: activity HEC0, sparks HEC0,
 activity HEC1, sparks HEC1, ...

[GUI] in the trace windown, enable/disable traces, but also
reorder them by just dragging and dropping

resample (morally) uniformly, before doing the percentiles --- but then
it's a mean, not a median any more, with enough sample points

25%/50%/75% percentile for pool size, in gnuplot, but see above about resampling
http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.6199
figure 15

merge adjacent 0 samples:
if we have equal adjacent samples we just take the second/last
can be done when it's still a list, before making the tree
simple linear pass
and lazy too

use the extra info about when the spark pool gets full and empty;
we know when the spark pool becomes empty because we can observe
that the threads evaluating sparks terminate; similarly, we know overflow
only occurs when the pool is full

consider making the graphs more accurate by drilling down the tree
to the base events at each slice borders:
they don't go down to the base events at each slice boundary
but only at the two viewport borders (hence the extra slices
at the ends dcoutts noticed).
The current state generally this results in smoothing the curve,
but a side-effect is that the graphs grow higher visually
(the max is higher) as the zoom level increases.

or increase the accuracy by dividing increments not by the slice
length (implicitly), but the length of the sum of tree node spans
that cover the slice, similarly as in gnuplot graphs


Far future:

[GUI] animate zoom level transitions:
ways to make the zoom in/out less confusing for users
(e.g. the sudden appearance of spikyness once thresholds)
animating the transitions would make it clearer
generate the bitmap of the higher resolution new view,
and animate it expanding to cover the new view
it'd be quick since it's just bitmap scaling
so the user can see the region in the old view
that is expanding out to become the new view

[GUI] let the user set the interval size/scale,
as an advanced option, _separately_ for each graph stack,
each HEC, each visible region at the current zoom level,
each selected region (if they are implemented)

[GUI] a button for vertical zoom (clip graphs if they don't fit at that zoom)
and/or select regions of time in the view
and zoom only that region of display;

[GUI] an option to automatically change scale at zoom in to take
into account only the visible and smoothed part of the graphs

[GUI] select a region and display it in a separate tab
(e.g. next to the events tab) and/or show in the tab for that selected time
period how many sparks of each kind in that time: summary statistics
for points in time, or periods of time

[GUI] scroll around the graph image via a small zoomed out window
"The Information Mural: A Technique for Displaying
and Navigating Large Information Spaces"

[GUI] label coloured areas with a mouseover, according to what they represent

look for some other parallel programs to test

use adaptive interval, depending on the sample density at the viewed fragment

perhaps, depending on sample density, alternate between raw data,
min/max, percentiles; so the raw data line slowly explodes into a band,
a big smudge, like a string of beads, that gets even more detailed
and perhaps wider, when data density/uniformity allows it;
in other words: a thin line means we only guess that's where the data might be
a thicker one, with mix/max means we have some data,
but too irregular/scarce to say more, and full thickness line,
with percentiles means we have enough data or evenly distributed enough
to say all

perhaps we should change the spark event sampling to emit events
every N sparks rather than at GC; but only if experiments (do more accurate
sampling and compare the general look of the graphs)
show that linear extrapolation of the GC data is not correct
(large spark transitions happen in the long periods between GC
and we don't know when exactly) (the 4K pool size guarantees that at least
with large visible absolute spark transition, the invisible transitions
can't be huge in proportion to the visible ones, so then linear extrapolaton
is correct))


Unrelated threadscope bugs:

the vertical blue line vanishes is some zoom levels

sideways scrolling leaves artifacts (e.g., the thicker fragments of the flat line at the end of the Activity graph)

sometimes 2 labels are written on top of each other even at max zoom, e.g. "thread 3 yielding" and "thread 3 is runnable"

may be a feature: filling graphs with colours is from line 1 upwards,
not line 0, so lines at level 0 seem under the filled area, not level with it
